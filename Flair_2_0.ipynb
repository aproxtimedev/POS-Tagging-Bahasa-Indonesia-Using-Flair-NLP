{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair 2.0",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "en9bUDg3P6Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byjn8iEai1gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, BertEmbeddings\n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N8O7y3ezxH2",
        "colab_type": "code",
        "outputId": "8e197117-f7f9-427d-ca5d-dbe33a0f996d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1. get the corpus\n",
        "corpus = NLPTaskDataFetcher.load_corpus(NLPTask.UD_INDONESIAN)\n",
        "\n",
        "# 2. what tag do we want to predict?\n",
        "tag_type = 'upos'\n",
        "\n",
        "# 3. make the tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "print(tag_dictionary.idx2item)\n",
        "\n",
        "# 4. initialize embeddings\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "    WordEmbeddings('id-crawl'),\n",
        "    WordEmbeddings('id'),\n",
        "    #WordEmbeddings('glove'),\n",
        "    #BertEmbeddings('bert-base-multilingual-cased')\n",
        "]\n",
        "\n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "from flair.models import SequenceTagger\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                        embeddings=embeddings,\n",
        "                                        tag_dictionary=tag_dictionary,\n",
        "                                        tag_type=tag_type,\n",
        "                                        use_crf=True)\n",
        "\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "# 7. start training\n",
        "trainer.train('resources/taggers/example-universal-pos',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-02 06:37:09,234 Reading data from /root/.flair/datasets/ud_indonesian\n",
            "2019-10-02 06:37:09,236 Train: /root/.flair/datasets/ud_indonesian/id_gsd-ud-train.conllu\n",
            "2019-10-02 06:37:09,239 Dev: /root/.flair/datasets/ud_indonesian/id_gsd-ud-dev.conllu\n",
            "2019-10-02 06:37:09,241 Test: /root/.flair/datasets/ud_indonesian/id_gsd-ud-test.conllu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated function (or staticmethod) load_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:218: DeprecationWarning: Call to deprecated function (or staticmethod) load_ud_corpus. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  return NLPTaskDataFetcher.load_ud_corpus(data_folder)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:384: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_train: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(train_file)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:385: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_test: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(test_file)\n",
            "/usr/local/lib/python3.6/dist-packages/flair/data_fetcher.py:386: DeprecationWarning: Call to deprecated function (or staticmethod) read_conll_ud. (Use 'flair.datasets' instead.) -- Deprecated since version 0.4.1.\n",
            "  sentences_dev: List[Sentence] = NLPTaskDataFetcher.read_conll_ud(dev_file)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[b'<unk>', b'O', b'PROPN', b'AUX', b'DET', b'NOUN', b'PRON', b'VERB', b'ADP', b'PUNCT', b'ADV', b'CCONJ', b'SCONJ', b'NUM', b'ADJ', b'PART', b'SYM', b'X', b'<START>', b'<STOP>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-10-02 06:37:26,876 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,883 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('id-crawl')\n",
            "    (list_embedding_1): WordEmbeddings('id')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=600, out_features=600, bias=True)\n",
            "  (rnn): LSTM(600, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=20, bias=True)\n",
            ")\"\n",
            "2019-10-02 06:37:26,886 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,890 Corpus: \"Corpus: 4477 train + 559 dev + 557 test sentences\"\n",
            "2019-10-02 06:37:26,893 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,895 Parameters:\n",
            "2019-10-02 06:37:26,898  - learning_rate: \"0.1\"\n",
            "2019-10-02 06:37:26,899  - mini_batch_size: \"32\"\n",
            "2019-10-02 06:37:26,903  - patience: \"3\"\n",
            "2019-10-02 06:37:26,906  - anneal_factor: \"0.5\"\n",
            "2019-10-02 06:37:26,909  - max_epochs: \"10\"\n",
            "2019-10-02 06:37:26,911  - shuffle: \"True\"\n",
            "2019-10-02 06:37:26,913  - train_with_dev: \"False\"\n",
            "2019-10-02 06:37:26,915 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,917 Model training base path: \"resources/taggers/example-universal-pos\"\n",
            "2019-10-02 06:37:26,920 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,930 Device: cuda:0\n",
            "2019-10-02 06:37:26,935 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:26,936 Embeddings storage mode: cpu\n",
            "2019-10-02 06:37:26,938 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:37:27,260 epoch 1 - iter 0/140 - loss 72.29892731 - samples/sec: 1398.05\n",
            "2019-10-02 06:37:32,041 epoch 1 - iter 14/140 - loss 55.98152669 - samples/sec: 94.05\n",
            "2019-10-02 06:37:36,384 epoch 1 - iter 28/140 - loss 48.51513810 - samples/sec: 103.55\n",
            "2019-10-02 06:37:40,898 epoch 1 - iter 42/140 - loss 43.36176393 - samples/sec: 99.59\n",
            "2019-10-02 06:37:45,189 epoch 1 - iter 56/140 - loss 39.78789972 - samples/sec: 104.86\n",
            "2019-10-02 06:37:49,625 epoch 1 - iter 70/140 - loss 37.06793960 - samples/sec: 101.36\n",
            "2019-10-02 06:37:54,075 epoch 1 - iter 84/140 - loss 34.79875001 - samples/sec: 101.08\n",
            "2019-10-02 06:37:58,353 epoch 1 - iter 98/140 - loss 33.04733929 - samples/sec: 105.14\n",
            "2019-10-02 06:38:02,655 epoch 1 - iter 112/140 - loss 31.40239945 - samples/sec: 104.55\n",
            "2019-10-02 06:38:06,624 epoch 1 - iter 126/140 - loss 29.79799653 - samples/sec: 113.37\n",
            "2019-10-02 06:38:10,626 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:38:10,627 EPOCH 1 done: loss 28.6202 - lr 0.1000\n",
            "2019-10-02 06:38:17,924 DEV : loss 12.866442680358887 - score 0.8175\n",
            "2019-10-02 06:38:17,967 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:38:34,917 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:38:35,185 epoch 2 - iter 0/140 - loss 17.08151627 - samples/sec: 1857.93\n",
            "2019-10-02 06:38:38,156 epoch 2 - iter 14/140 - loss 14.93183238 - samples/sec: 154.19\n",
            "2019-10-02 06:38:41,025 epoch 2 - iter 28/140 - loss 14.64831063 - samples/sec: 157.05\n",
            "2019-10-02 06:38:44,156 epoch 2 - iter 42/140 - loss 14.98768906 - samples/sec: 143.97\n",
            "2019-10-02 06:38:47,308 epoch 2 - iter 56/140 - loss 15.12048435 - samples/sec: 142.99\n",
            "2019-10-02 06:38:50,415 epoch 2 - iter 70/140 - loss 15.03375622 - samples/sec: 145.04\n",
            "2019-10-02 06:38:53,612 epoch 2 - iter 84/140 - loss 14.83502453 - samples/sec: 141.00\n",
            "2019-10-02 06:38:56,458 epoch 2 - iter 98/140 - loss 14.44943571 - samples/sec: 158.46\n",
            "2019-10-02 06:38:59,395 epoch 2 - iter 112/140 - loss 14.22299707 - samples/sec: 153.45\n",
            "2019-10-02 06:39:02,799 epoch 2 - iter 126/140 - loss 14.06653169 - samples/sec: 132.25\n",
            "2019-10-02 06:39:05,519 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:39:05,520 EPOCH 2 done: loss 13.9192 - lr 0.1000\n",
            "2019-10-02 06:39:11,165 DEV : loss 8.648719787597656 - score 0.8693\n",
            "2019-10-02 06:39:11,207 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:39:27,508 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:39:27,683 epoch 3 - iter 0/140 - loss 11.61858082 - samples/sec: 2867.70\n",
            "2019-10-02 06:39:30,938 epoch 3 - iter 14/140 - loss 11.86696828 - samples/sec: 138.36\n",
            "2019-10-02 06:39:33,911 epoch 3 - iter 28/140 - loss 11.80156688 - samples/sec: 151.56\n",
            "2019-10-02 06:39:37,029 epoch 3 - iter 42/140 - loss 11.61846235 - samples/sec: 144.63\n",
            "2019-10-02 06:39:40,326 epoch 3 - iter 56/140 - loss 11.77209606 - samples/sec: 136.58\n",
            "2019-10-02 06:39:43,118 epoch 3 - iter 70/140 - loss 11.68659803 - samples/sec: 161.41\n",
            "2019-10-02 06:39:45,851 epoch 3 - iter 84/140 - loss 11.65528810 - samples/sec: 165.04\n",
            "2019-10-02 06:39:48,837 epoch 3 - iter 98/140 - loss 11.60665409 - samples/sec: 151.08\n",
            "2019-10-02 06:39:51,499 epoch 3 - iter 112/140 - loss 11.59749582 - samples/sec: 169.52\n",
            "2019-10-02 06:39:54,779 epoch 3 - iter 126/140 - loss 11.44680555 - samples/sec: 137.32\n",
            "2019-10-02 06:39:57,562 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:39:57,564 EPOCH 3 done: loss 11.3220 - lr 0.1000\n",
            "2019-10-02 06:40:03,243 DEV : loss 7.53046178817749 - score 0.892\n",
            "2019-10-02 06:40:03,285 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:40:19,327 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:40:19,720 epoch 4 - iter 0/140 - loss 8.29433632 - samples/sec: 2411.52\n",
            "2019-10-02 06:40:22,986 epoch 4 - iter 14/140 - loss 10.27176965 - samples/sec: 137.81\n",
            "2019-10-02 06:40:25,734 epoch 4 - iter 28/140 - loss 10.36041944 - samples/sec: 164.12\n",
            "2019-10-02 06:40:28,753 epoch 4 - iter 42/140 - loss 10.66153331 - samples/sec: 149.34\n",
            "2019-10-02 06:40:32,379 epoch 4 - iter 56/140 - loss 10.71849533 - samples/sec: 124.33\n",
            "2019-10-02 06:40:35,428 epoch 4 - iter 70/140 - loss 10.53064787 - samples/sec: 147.81\n",
            "2019-10-02 06:40:38,513 epoch 4 - iter 84/140 - loss 10.39242398 - samples/sec: 146.13\n",
            "2019-10-02 06:40:41,166 epoch 4 - iter 98/140 - loss 10.28169020 - samples/sec: 169.93\n",
            "2019-10-02 06:40:44,150 epoch 4 - iter 112/140 - loss 10.29040308 - samples/sec: 151.04\n",
            "2019-10-02 06:40:47,054 epoch 4 - iter 126/140 - loss 10.31507456 - samples/sec: 155.29\n",
            "2019-10-02 06:40:49,905 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:40:49,907 EPOCH 4 done: loss 10.2771 - lr 0.1000\n",
            "2019-10-02 06:40:55,494 DEV : loss 6.577473163604736 - score 0.9075\n",
            "2019-10-02 06:40:55,546 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:41:11,647 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:41:11,821 epoch 5 - iter 0/140 - loss 8.04693031 - samples/sec: 2710.24\n",
            "2019-10-02 06:41:14,659 epoch 5 - iter 14/140 - loss 9.61421226 - samples/sec: 158.84\n",
            "2019-10-02 06:41:17,353 epoch 5 - iter 28/140 - loss 9.50473014 - samples/sec: 167.28\n",
            "2019-10-02 06:41:20,377 epoch 5 - iter 42/140 - loss 9.99779738 - samples/sec: 148.96\n",
            "2019-10-02 06:41:23,338 epoch 5 - iter 56/140 - loss 9.89852994 - samples/sec: 152.23\n",
            "2019-10-02 06:41:26,632 epoch 5 - iter 70/140 - loss 9.86188961 - samples/sec: 136.76\n",
            "2019-10-02 06:41:29,671 epoch 5 - iter 84/140 - loss 9.81989397 - samples/sec: 148.28\n",
            "2019-10-02 06:41:33,009 epoch 5 - iter 98/140 - loss 9.85565977 - samples/sec: 135.03\n",
            "2019-10-02 06:41:36,199 epoch 5 - iter 112/140 - loss 9.82842282 - samples/sec: 141.36\n",
            "2019-10-02 06:41:39,514 epoch 5 - iter 126/140 - loss 9.84986650 - samples/sec: 136.07\n",
            "2019-10-02 06:41:42,142 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:41:42,143 EPOCH 5 done: loss 9.8212 - lr 0.1000\n",
            "2019-10-02 06:41:47,720 DEV : loss 6.348021030426025 - score 0.91\n",
            "2019-10-02 06:41:47,764 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:42:03,964 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:42:04,129 epoch 6 - iter 0/140 - loss 6.65541697 - samples/sec: 2804.12\n",
            "2019-10-02 06:42:07,385 epoch 6 - iter 14/140 - loss 9.07330885 - samples/sec: 138.28\n",
            "2019-10-02 06:42:10,458 epoch 6 - iter 28/140 - loss 9.47228507 - samples/sec: 146.61\n",
            "2019-10-02 06:42:13,641 epoch 6 - iter 42/140 - loss 9.49246063 - samples/sec: 141.55\n",
            "2019-10-02 06:42:16,502 epoch 6 - iter 56/140 - loss 9.33793618 - samples/sec: 157.70\n",
            "2019-10-02 06:42:19,998 epoch 6 - iter 70/140 - loss 9.53356568 - samples/sec: 128.76\n",
            "2019-10-02 06:42:22,911 epoch 6 - iter 84/140 - loss 9.46237156 - samples/sec: 154.81\n",
            "2019-10-02 06:42:25,775 epoch 6 - iter 98/140 - loss 9.36679176 - samples/sec: 157.51\n",
            "2019-10-02 06:42:28,838 epoch 6 - iter 112/140 - loss 9.25380391 - samples/sec: 147.22\n",
            "2019-10-02 06:42:31,934 epoch 6 - iter 126/140 - loss 9.29169012 - samples/sec: 145.46\n",
            "2019-10-02 06:42:34,906 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:42:34,907 EPOCH 6 done: loss 9.2730 - lr 0.1000\n",
            "2019-10-02 06:42:40,584 DEV : loss 6.164815902709961 - score 0.9116\n",
            "2019-10-02 06:42:40,625 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:42:56,725 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:42:57,267 epoch 7 - iter 0/140 - loss 9.87750626 - samples/sec: 881.24\n",
            "2019-10-02 06:43:00,529 epoch 7 - iter 14/140 - loss 8.95465295 - samples/sec: 137.97\n",
            "2019-10-02 06:43:03,733 epoch 7 - iter 28/140 - loss 9.04014872 - samples/sec: 140.56\n",
            "2019-10-02 06:43:06,560 epoch 7 - iter 42/140 - loss 9.15875341 - samples/sec: 159.49\n",
            "2019-10-02 06:43:09,525 epoch 7 - iter 56/140 - loss 9.09254472 - samples/sec: 152.22\n",
            "2019-10-02 06:43:12,773 epoch 7 - iter 70/140 - loss 8.98230694 - samples/sec: 138.66\n",
            "2019-10-02 06:43:15,754 epoch 7 - iter 84/140 - loss 8.96397915 - samples/sec: 151.16\n",
            "2019-10-02 06:43:18,518 epoch 7 - iter 98/140 - loss 8.90059344 - samples/sec: 163.20\n",
            "2019-10-02 06:43:21,633 epoch 7 - iter 112/140 - loss 8.93479196 - samples/sec: 144.63\n",
            "2019-10-02 06:43:24,760 epoch 7 - iter 126/140 - loss 8.92915763 - samples/sec: 144.03\n",
            "2019-10-02 06:43:27,529 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:43:27,533 EPOCH 7 done: loss 9.0118 - lr 0.1000\n",
            "2019-10-02 06:43:33,150 DEV : loss 5.9445576667785645 - score 0.9156\n",
            "2019-10-02 06:43:33,192 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:43:49,410 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:43:49,661 epoch 8 - iter 0/140 - loss 7.76694965 - samples/sec: 2040.34\n",
            "2019-10-02 06:43:52,667 epoch 8 - iter 14/140 - loss 8.55466248 - samples/sec: 149.90\n",
            "2019-10-02 06:43:55,919 epoch 8 - iter 28/140 - loss 8.81779480 - samples/sec: 138.59\n",
            "2019-10-02 06:43:59,359 epoch 8 - iter 42/140 - loss 8.90785244 - samples/sec: 130.92\n",
            "2019-10-02 06:44:02,394 epoch 8 - iter 56/140 - loss 8.79081138 - samples/sec: 148.53\n",
            "2019-10-02 06:44:06,174 epoch 8 - iter 70/140 - loss 9.02134238 - samples/sec: 119.08\n",
            "2019-10-02 06:44:09,152 epoch 8 - iter 84/140 - loss 9.03863255 - samples/sec: 151.27\n",
            "2019-10-02 06:44:11,873 epoch 8 - iter 98/140 - loss 8.85288018 - samples/sec: 165.69\n",
            "2019-10-02 06:44:14,701 epoch 8 - iter 112/140 - loss 8.89230082 - samples/sec: 159.55\n",
            "2019-10-02 06:44:17,889 epoch 8 - iter 126/140 - loss 8.86582709 - samples/sec: 141.35\n",
            "2019-10-02 06:44:20,504 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:44:20,506 EPOCH 8 done: loss 8.8402 - lr 0.1000\n",
            "2019-10-02 06:44:26,183 DEV : loss 5.925971984863281 - score 0.9141\n",
            "2019-10-02 06:44:26,231 BAD EPOCHS (no improvement): 1\n",
            "2019-10-02 06:44:26,234 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:44:26,461 epoch 9 - iter 0/140 - loss 6.59710360 - samples/sec: 1991.28\n",
            "2019-10-02 06:44:29,516 epoch 9 - iter 14/140 - loss 8.30681299 - samples/sec: 147.43\n",
            "2019-10-02 06:44:33,042 epoch 9 - iter 28/140 - loss 8.53307320 - samples/sec: 127.79\n",
            "2019-10-02 06:44:35,918 epoch 9 - iter 42/140 - loss 8.57182956 - samples/sec: 156.84\n",
            "2019-10-02 06:44:38,946 epoch 9 - iter 56/140 - loss 8.46900755 - samples/sec: 148.83\n",
            "2019-10-02 06:44:41,859 epoch 9 - iter 70/140 - loss 8.56279689 - samples/sec: 154.70\n",
            "2019-10-02 06:44:45,451 epoch 9 - iter 84/140 - loss 8.59018437 - samples/sec: 125.30\n",
            "2019-10-02 06:44:48,295 epoch 9 - iter 98/140 - loss 8.51000415 - samples/sec: 158.62\n",
            "2019-10-02 06:44:51,544 epoch 9 - iter 112/140 - loss 8.54889085 - samples/sec: 138.61\n",
            "2019-10-02 06:44:54,486 epoch 9 - iter 126/140 - loss 8.52137474 - samples/sec: 153.25\n",
            "2019-10-02 06:44:57,119 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:44:57,121 EPOCH 9 done: loss 8.6175 - lr 0.1000\n",
            "2019-10-02 06:45:02,771 DEV : loss 5.796445369720459 - score 0.9167\n",
            "2019-10-02 06:45:02,812 BAD EPOCHS (no improvement): 0\n",
            "2019-10-02 06:45:19,046 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:45:19,280 epoch 10 - iter 0/140 - loss 8.09962463 - samples/sec: 1947.83\n",
            "2019-10-02 06:45:22,426 epoch 10 - iter 14/140 - loss 8.41683963 - samples/sec: 143.11\n",
            "2019-10-02 06:45:25,514 epoch 10 - iter 28/140 - loss 8.75762760 - samples/sec: 145.96\n",
            "2019-10-02 06:45:28,713 epoch 10 - iter 42/140 - loss 8.61668616 - samples/sec: 140.84\n",
            "2019-10-02 06:45:31,582 epoch 10 - iter 56/140 - loss 8.68700252 - samples/sec: 157.22\n",
            "2019-10-02 06:45:34,779 epoch 10 - iter 70/140 - loss 8.66197569 - samples/sec: 140.91\n",
            "2019-10-02 06:45:37,683 epoch 10 - iter 84/140 - loss 8.67945493 - samples/sec: 155.29\n",
            "2019-10-02 06:45:40,869 epoch 10 - iter 98/140 - loss 8.64263787 - samples/sec: 141.48\n",
            "2019-10-02 06:45:44,183 epoch 10 - iter 112/140 - loss 8.63141727 - samples/sec: 135.89\n",
            "2019-10-02 06:45:46,945 epoch 10 - iter 126/140 - loss 8.50887854 - samples/sec: 163.25\n",
            "2019-10-02 06:45:49,534 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:45:49,535 EPOCH 10 done: loss 8.4694 - lr 0.1000\n",
            "2019-10-02 06:45:55,201 DEV : loss 5.78936767578125 - score 0.9142\n",
            "2019-10-02 06:45:55,243 BAD EPOCHS (no improvement): 1\n",
            "2019-10-02 06:46:11,427 ----------------------------------------------------------------------------------------------------\n",
            "2019-10-02 06:46:11,444 Testing using best model ...\n",
            "2019-10-02 06:46:11,448 loading file resources/taggers/example-universal-pos/best-model.pt\n",
            "2019-10-02 06:47:05,766 0.9222\t0.9222\t0.9222\n",
            "2019-10-02 06:47:05,770 \n",
            "MICRO_AVG: acc 0.8557 - f1-score 0.9222\n",
            "MACRO_AVG: acc 0.7894 - f1-score 0.85316875\n",
            "ADJ        tp: 271 - fp: 48 - fn: 154 - tn: 271 - precision: 0.8495 - recall: 0.6376 - accuracy: 0.5729 - f1-score: 0.7285\n",
            "ADP        tp: 1115 - fp: 89 - fn: 38 - tn: 1115 - precision: 0.9261 - recall: 0.9670 - accuracy: 0.8977 - f1-score: 0.9461\n",
            "ADV        tp: 424 - fp: 104 - fn: 66 - tn: 424 - precision: 0.8030 - recall: 0.8653 - accuracy: 0.7138 - f1-score: 0.8330\n",
            "AUX        tp: 96 - fp: 1 - fn: 0 - tn: 96 - precision: 0.9897 - recall: 1.0000 - accuracy: 0.9897 - f1-score: 0.9948\n",
            "CCONJ      tp: 341 - fp: 4 - fn: 34 - tn: 341 - precision: 0.9884 - recall: 0.9093 - accuracy: 0.8997 - f1-score: 0.9472\n",
            "DET        tp: 347 - fp: 25 - fn: 27 - tn: 347 - precision: 0.9328 - recall: 0.9278 - accuracy: 0.8697 - f1-score: 0.9303\n",
            "NOUN       tp: 2315 - fp: 313 - fn: 240 - tn: 2315 - precision: 0.8809 - recall: 0.9061 - accuracy: 0.8072 - f1-score: 0.8933\n",
            "NUM        tp: 380 - fp: 25 - fn: 27 - tn: 380 - precision: 0.9383 - recall: 0.9337 - accuracy: 0.8796 - f1-score: 0.9360\n",
            "PART       tp: 42 - fp: 2 - fn: 7 - tn: 42 - precision: 0.9545 - recall: 0.8571 - accuracy: 0.8235 - f1-score: 0.9032\n",
            "PRON       tp: 467 - fp: 8 - fn: 31 - tn: 467 - precision: 0.9832 - recall: 0.9378 - accuracy: 0.9229 - f1-score: 0.9600\n",
            "PROPN      tp: 2038 - fp: 184 - fn: 173 - tn: 2038 - precision: 0.9172 - recall: 0.9218 - accuracy: 0.8509 - f1-score: 0.9195\n",
            "PUNCT      tp: 1723 - fp: 10 - fn: 1 - tn: 1723 - precision: 0.9942 - recall: 0.9994 - accuracy: 0.9937 - f1-score: 0.9968\n",
            "SCONJ      tp: 112 - fp: 27 - fn: 30 - tn: 112 - precision: 0.8058 - recall: 0.7887 - accuracy: 0.6627 - f1-score: 0.7972\n",
            "SYM        tp: 26 - fp: 0 - fn: 4 - tn: 26 - precision: 1.0000 - recall: 0.8667 - accuracy: 0.8667 - f1-score: 0.9286\n",
            "VERB       tp: 1167 - fp: 76 - fn: 83 - tn: 1167 - precision: 0.9389 - recall: 0.9336 - accuracy: 0.8801 - f1-score: 0.9362\n",
            "X          tp: 0 - fp: 0 - fn: 1 - tn: 0 - precision: 0.0000 - recall: 0.0000 - accuracy: 0.0000 - f1-score: 0.0000\n",
            "2019-10-02 06:47:05,773 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(12.8664, device='cuda:0'),\n",
              "  tensor(8.6487, device='cuda:0'),\n",
              "  tensor(7.5305, device='cuda:0'),\n",
              "  tensor(6.5775, device='cuda:0'),\n",
              "  tensor(6.3480, device='cuda:0'),\n",
              "  tensor(6.1648, device='cuda:0'),\n",
              "  tensor(5.9446, device='cuda:0'),\n",
              "  tensor(5.9260, device='cuda:0'),\n",
              "  tensor(5.7964, device='cuda:0'),\n",
              "  tensor(5.7894, device='cuda:0')],\n",
              " 'dev_score_history': [0.8175,\n",
              "  0.8693,\n",
              "  0.892,\n",
              "  0.9075,\n",
              "  0.91,\n",
              "  0.9116,\n",
              "  0.9156,\n",
              "  0.9141,\n",
              "  0.9167,\n",
              "  0.9142],\n",
              " 'test_score': 0.9222,\n",
              " 'train_loss_history': [28.620167078290667,\n",
              "  13.919212940761021,\n",
              "  11.322017758233207,\n",
              "  10.277066789354597,\n",
              "  9.821163579395838,\n",
              "  9.272978401184082,\n",
              "  9.011836685453142,\n",
              "  8.840235917908805,\n",
              "  8.617510696819851,\n",
              "  8.46943097795759]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvmmuVf7cPs",
        "colab_type": "code",
        "outputId": "5e6caba4-57a7-469f-d0d6-46c3ce8ed25e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sentence = Sentence('saya dan dia kemarin pegi ke pasar bersama untuk membeli jeru')\n",
        "tag_pos = SequenceTagger.load('resources/taggers/example-universal-pos/best-model.pt')\n",
        "tag_pos.predict(sentence)\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-02 06:50:30,237 loading file resources/taggers/example-universal-pos/best-model.pt\n",
            "saya <PRON> dan <CCONJ> dia <PRON> kemarin <VERB> pegi <NOUN> ke <ADP> pasar <NOUN> bersama <ADP> untuk <ADP> membeli <VERB> jeru <NOUN>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}